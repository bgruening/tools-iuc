<tool id="sleuth" name="Sleuth" version="@TOOL_VERSION@+galaxy@SUFFIX_VERSION@">
    <description>differential expression analysis</description>
    <macros>
        <import>macros.xml</import>
    </macros>
    <expand macro='requirements'/>
    <expand macro='xrefs'/>
    <stdio>
        <regex match="Execution halted"
           source="both"
           level="fatal"
           description="Execution halted." />
        <regex match="Error in"
           source="both"
           level="fatal"
           description="An undefined error occurred, please check your input carefully and contact your administrator." />
        <regex match="Fatal error"
           source="both"
           level="fatal"
           description="An undefined error occurred, please check your input carefully and contact your administrator." />
    </stdio>
    <version_command><![CDATA[
echo $(R --version | grep version | grep -v GNU)", DESeq2 version" $(R --vanilla --slave -e "library(DESeq2); cat(sessionInfo()\$otherPkgs\$DESeq2\$Version)" 2> /dev/null | grep -v -i "WARNING: ")
    ]]></version_command>
    <command><![CDATA[
        #set $cond1_files = list()
        #set $cond2_files = list()
        #for $i, $count in enumerate(str($first_factor.trans_counts).split(","))
            #set $fname = str($first_factor.factorLevel) + "_" + str($i)  + '.h5'
            ln -s '${count}' "${fname}" &&
            $cond1_files.append($fname)
        #end for
        #for $i, $count in enumerate(str($second_factor.trans_counts).split(","))
            #set $fname = str($second_factor.factorLevel) + "_"  + str($i) + '.h5'
            ln -s '${count}' "${fname}" &&
            $cond2_files.append($fname)
        #end for
        Rscript '${__tool_directory__}/sleuth.R'
            --factorLevel1 '${first_factor.factorLevel}'
            #for $count in $cond1_files
                --factorLevel1_counts '${count}'
            #end for
            --factorLevel2 '${second_factor.factorLevel}'
            #for $count in $cond2_files
                --factorLevel2_counts '${count}'
            #end for
            --cores  \${GALAXY_SLOTS:-1}
            $advanced_options.normalization
            --nbins $advanced_options.nbins
            --lwr $advanced_options.lwr
            --upr $advanced_options.upr
    ]]></command>
    <inputs>
        <section name="first_factor" title="1: Factor level" expanded="true">
            <param name="factorLevel" type="text" value="FactorLevel" label="Factor level"
                help="Only letters, numbers and underscores will be retained in this field">
                <sanitizer>
                    <valid initial="string.letters,string.digits"><add value="_" /></valid>
                </sanitizer>
            </param>
            <param name="trans_counts" type="data" format="h5" multiple="true" label="Transcript-level expression measurements"/> 
        </section>
        <section name="second_factor" title="2: Factor level" expanded="true">
            <param name="factorLevel" type="text" value="FactorLevel" label="Factor level"
                help="Only letters, numbers and underscores will be retained in this field">
                <sanitizer>
                    <valid initial="string.letters,string.digits"><add value="_" /></valid>
                </sanitizer>
            </param>
            <param name="trans_counts" type="data" format="h5" multiple="true" label="Transcript-level expression measurements"/> 
        </section>
        <section name="advanced_options" title="Advanced options" expanded="true">
            <param argument="normalization" type="boolean" truevalue="--normalize" falsevalue="" checked="true" label="Normalize data" 
                help="If this is set to false, bootstraps will not be read and transformation of the data will not be done. This should 
                    only be set to false if one desires to do a quick check of the raw data. " />
            <param argument="nbins" type="integer" min="0" value="100" label="NBins" help="The number of bins that the data should be 
                split for the sliding window shrinkage using the mean-variance curve." />
            <param argument="lwr" type="float" min="0" max="1" value="0.25" label="LWR" help="The lower range of variances within each 
                bin that should be included for the shrinkage procedure. " />
            <param argument="upr" type="float" min="0" max="1" value="0.75" label="UPR" help="The upper range of variances within each 
                bin that should be included for the shrinkage procedure." />
        </section>
    </inputs>
    <outputs>
        <data name="sleuth_table" from_work_dir="sleuth_table.tab" format="tabular" label="${tool.name} on ${on_string}: DE table"/>
        <data name="pca_plot" from_work_dir="pca_plot.pdf" format="pdf" label="${tool.name} on ${on_string}: PCA plot"/>
        <data name="density_plot" from_work_dir="group_density.pdf" format="pdf" label="${tool.name} on ${on_string}: density plot"/>
    </outputs>
    <tests>
        <test expect_num_outputs="3">
            <section name="first_factor">
                <param name="factorLevel" value="Control"/>
                <param name="trans_counts" value="kallisto_output_01.h5,kallisto_output_02.h5"/>
            </section>
            <section name="second_factor">
                <param name="factorLevel" value="Cancer"/>
                <param name="trans_counts" value="kallisto_output_03.h5,kallisto_output_04.h5"/>
            </section>
            <section name="advanced_options">
                <param name="normalization" value="true"/>
                <param name="nbins" value="100"/>
                <param name="lwr" value="0.25"/>
                <param name="upr" value="0.75"/>
            </section>
            <output name="sleuth_table" file="test01_table.tab" ftype="tabular"/>
            <output name="pca_plot" file="test01_pca.pdf" ftype="pdf" compare="sim_size"/>
            <output name="density_plot" file="test01_density.pdf" ftype="pdf" compare="sim_size"/>
        </test>
    </tests>
    <help><![CDATA[

.. class:: infomark

**Purpose**

Sleuth is a tool for the analysis and comparison of multiple related RNA-Seq experiments. Key features include:

- The ability to perform both transcript-level and gene-level analysis.
- Compatibility with kallisto enabling a fast and accurate workflow from reads to results.
- The use of boostraps to ascertain and correct for technical variation in experiments.
- An interactive app for exploratory data analysis.

To use sleuth, RNA-Seq data must first be quantified with kallisto, which is a program for very fast RNA-Seq quantification based on 
pseudo-alignment. An important feature of kallisto is that it outputs bootstraps along with the estimates of transcript abundances. 
These can serve as proxies for technical replicates, allowing for an ascertainment of the variability in estimates due to the random 
processes underlying RNA-Seq as well as the statistical procedure of read assignment. kallisto can quantify 30 million human reads in 
less than 3 minutes on a Mac desktop computer using only the read sequences and a transcriptome index that itself takes less than 10 
minutes to build. sleuth has been designed to work seamlessly and efficiently with kallisto, and therefore RNA-Seq analysis with kallisto 
and sleuth is tractable on a laptop computer in a matter of minutes. 

    ]]></help>
    <expand macro="citations" />
</tool>
